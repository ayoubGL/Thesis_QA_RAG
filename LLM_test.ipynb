{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3217f58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vv/jld3_3hn5fz42wp20lz51yxm0000gn/T/ipykernel_98973/49787312.py:6: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
      "  llm = Ollama(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're referring to the winners of various football competitions in 2022!\n",
      "\n",
      "Here are some notable ones:\n",
      "\n",
      "1. **FIFA World Cup Qatar 2022**:\n",
      "\t* Winners: Argentina (won against France in the final on December 18, 2022)\n",
      "\t* Golden Ball (best player): Lionel Messi\n",
      "\t* Golden Glove (best goalkeeper): Emiliano Mart√≠nez\n",
      "2. **UEFA Champions League 2021-22**:\n",
      "\t* Winners: Real Madrid (beat Liverpool 1-0 in the final on May 28, 2022)\n",
      "3. **English Premier League 2021-22**:\n",
      "\t* Winners: Manchester City\n",
      "4. **La Liga 2021-22**:\n",
      "\t* Winners: Barcelona (on points average, as the team finished with the same number of points but fewer goals conceded than Real Madrid)\n",
      "5. **Bundesliga 2021-22**:\n",
      "\t* Winners: Bayern Munich\n",
      "6. **Serie A 2021-22**:\n",
      "\t* Winners: AC Milan\n",
      "7. **UEFA Europa League 2021-22**:\n",
      "\t* Winners: Eintracht Frankfurt (beat Rangers 2-1 in the final on May 18, 2022)\n",
      "8. **Copa Libertadores 2022**:\n",
      "\t* Winners: Independiente del Valle (from Ecuador)\n",
      "\n",
      "These are just a few examples of football winners from 2022. If you're interested in more information or specific competitions, feel free to ask!"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "\n",
    "llm = Ollama(\n",
    "    model = \"llama3.1\", callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    ")\n",
    "answer = llm.invoke(\"football winner 2022\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4c0a15",
   "metadata": {},
   "source": [
    "### Text Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4838608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_kappa = \"./pdfs/Kappe.pdf\"\n",
    "loader = PyPDFLoader(pdf_kappa)\n",
    "\n",
    "# Load all pages and extract text content\n",
    "pages = [page.page_content for page in loader.lazy_load()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279ae227",
   "metadata": {},
   "source": [
    "### Semantic chunk to split the thesis\n",
    "Semantic chunking considers the relationship within the text. It divides the text into meaningful, semantically complete chunks.\n",
    "\n",
    "Semantic chunk involves taking the embeddings of every sentence in the document, comparing the similarity of all sentences with each other and then grouping sentences with the most similar embeddings together.\n",
    "\n",
    "- Emebedding Models:\n",
    "    - bge-small-en: very light and dedicate for retrieval-augmented language tasks. It's designed to officially handle tasks like passage retrieval and semantic similarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "baaab20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c407b3e7aa14b078f58a7e6a02632ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f50b4e733c444780baaf4ce451292b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_optimized.onnx:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f869b829f2147caab787012be2b038a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c0e38f224541948cb52cc294ba221b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f142e70f5e884673a42b499a14c180ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53324cbd7d30480e8d7b39093d673f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/701 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "\n",
    "\n",
    "embedding_model = FastEmbedEmbeddings(model_name=\"BAAI/bge-small-en\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ffe31ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastembed\n",
      "  Downloading fastembed-0.7.3-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.20 in /opt/anaconda3/envs/ML_env/lib/python3.10/site-packages (from fastembed) (0.33.1)\n",
      "Collecting loguru<0.8.0,>=0.7.2 (from fastembed)\n",
      "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting mmh3<6.0.0,>=4.1.0 (from fastembed)\n",
      "  Downloading mmh3-5.2.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/anaconda3/envs/ML_env/lib/python3.10/site-packages (from fastembed) (1.26.4)\n",
      "Collecting onnxruntime!=1.20.0,>=1.17.0 (from fastembed)\n",
      "  Downloading onnxruntime-1.22.1-cp310-cp310-macosx_13_0_universal2.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pillow<12.0.0,>=10.3.0 in /opt/anaconda3/envs/ML_env/lib/python3.10/site-packages (from fastembed) (11.2.1)\n",
      "Collecting py-rust-stemmers<0.2.0,>=0.1.0 (from fastembed)\n",
      "  Downloading py_rust_stemmers-0.1.5-cp310-cp310-macosx_10_12_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests<3.0,>=2.31 in /opt/anaconda3/envs/ML_env/lib/python3.10/site-packages (from fastembed) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<1.0,>=0.15 in /opt/anaconda3/envs/ML_env/lib/python3.10/site-packages (from fastembed) (0.21.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.66 in /opt/anaconda3/envs/ML_env/lib/python3.10/site-packages (from fastembed) (4.67.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/ML_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/ML_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/envs/ML_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/ML_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/ML_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/anaconda3/envs/ML_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (1.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/ML_env/lib/python3.10/site-packages (from requests<3.0,>=2.31->fastembed) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/ML_env/lib/python3.10/site-packages (from requests<3.0,>=2.31->fastembed) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/ML_env/lib/python3.10/site-packages (from requests<3.0,>=2.31->fastembed) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/ML_env/lib/python3.10/site-packages (from requests<3.0,>=2.31->fastembed) (2025.6.15)\n",
      "Collecting coloredlogs (from onnxruntime!=1.20.0,>=1.17.0->fastembed)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime!=1.20.0,>=1.17.0->fastembed)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/envs/ML_env/lib/python3.10/site-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (5.29.5)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/ML_env/lib/python3.10/site-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (1.14.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime!=1.20.0,>=1.17.0->fastembed)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/ML_env/lib/python3.10/site-packages (from sympy->onnxruntime!=1.20.0,>=1.17.0->fastembed) (1.3.0)\n",
      "Downloading fastembed-0.7.3-py3-none-any.whl (105 kB)\n",
      "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
      "Downloading mmh3-5.2.0-cp310-cp310-macosx_10_9_x86_64.whl (40 kB)\n",
      "Downloading py_rust_stemmers-0.1.5-cp310-cp310-macosx_10_12_x86_64.whl (286 kB)\n",
      "Downloading onnxruntime-1.22.1-cp310-cp310-macosx_13_0_universal2.whl (34.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Installing collected packages: py-rust-stemmers, flatbuffers, mmh3, loguru, humanfriendly, coloredlogs, onnxruntime, fastembed\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8/8\u001b[0m [fastembed]/8\u001b[0m [fastembed]e]y]\n",
      "\u001b[1A\u001b[2KSuccessfully installed coloredlogs-15.0.1 fastembed-0.7.3 flatbuffers-25.2.10 humanfriendly-10.0 loguru-0.7.3 mmh3-5.2.0 onnxruntime-1.22.1 py-rust-stemmers-0.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fastembed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8f9fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
